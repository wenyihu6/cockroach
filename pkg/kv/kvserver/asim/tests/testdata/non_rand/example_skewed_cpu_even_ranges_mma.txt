skip_under_ci
----

gen_cluster nodes=9 node_cpu_rate_capacity=5000000000
----

# The placement will be skewed, s.t. n1/s1, n2/s2 and n3/s3 will have all the
# replicas initially and n1/s1 will have every lease. Each range is initially
# 256 MiB.
gen_ranges ranges=36 min_key=1 max_key=10000 placement_type=replica_placement bytes=268435456
{s1,s2,s3}:1
----
{s1:*,s2,s3}:1

# 5ms of request CPU per access and 500Âµs of raft CPU per write @ 1000/s.
gen_load rate=1000 rw_ratio=0.95 min_block=100 max_block=100 request_cpu_per_access=5000000 raft_cpu_per_write=500000 min_key=1 max_key=10000
----

# Almost empty workload, which generates no CPU and small amount of writes
# over the second half of the keyspace, scattered over s4-s9.
gen_ranges ranges=72 min_key=10001 max_key=20000 placement_type=replica_placement bytes=268435456
{s4,s5,s6}:1
{s7,s8,s9}:1
----
{s4:*,s5,s6}:1
{s7:*,s8,s9}:1

gen_load rate=100 rw_ratio=0 min_block=128 max_block=128 min_key=10001 max_key=20000
----

setting split_queue_enabled=false
----

# TODO(tbg): it's interesting that sma-only does better on write throughput than
# mma-only. Looking at the graphs, the mma-only flavor is much slower in moving
# load around. Possibly a bug?
eval duration=35m samples=1 seed=42 cfgs=(sma-only,mma-only,mma-and-count) metrics=(cpu,leases,replicas,write_bytes_per_second)
----
cpu#1: last:  [s1=984642922, s2=1126669982, s3=703798726, s4=419425213, s5=432156047, s6=559114683, s7=142318086, s8=283346689, s9=424209084] (stddev=303225920.55, mean=563964603.56, sum=5075681432)
cpu#1: thrash_pct: [s1=14%, s2=49%, s3=47%, s4=9%, s5=9%, s6=11%, s7=4%, s8=14%, s9=25%]  (sum=182%)
leases#1: first: [s1=36, s2=0, s3=0, s4=36, s5=0, s6=0, s7=36, s8=0, s9=0] (stddev=16.97, mean=12.00, sum=108)
leases#1: last:  [s1=13, s2=12, s3=12, s4=17, s5=11, s6=9, s7=15, s8=10, s9=9] (stddev=2.54, mean=12.00, sum=108)
leases#1: thrash_pct: [s1=53%, s2=38%, s3=44%, s4=21%, s5=20%, s6=26%, s7=15%, s8=26%, s9=37%]  (sum=281%)
replicas#1: first: [s1=36, s2=36, s3=36, s4=36, s5=36, s6=36, s7=36, s8=36, s9=36] (stddev=0.00, mean=36.00, sum=324)
replicas#1: last:  [s1=36, s2=37, s3=33, s4=37, s5=36, s6=36, s7=36, s8=35, s9=38] (stddev=1.33, mean=36.00, sum=324)
replicas#1: thrash_pct: [s1=433%, s2=402%, s3=672%, s4=135%, s5=117%, s6=217%, s7=117%, s8=218%, s9=403%]  (sum=2713%)
write_bytes_per_second#1: last:  [s1=5619, s2=5639, s3=5275, s4=6269, s5=6137, s6=6150, s7=6187, s8=5861, s9=6290] (stddev=336.10, mean=5936.33, sum=53427)
write_bytes_per_second#1: thrash_pct: [s1=572%, s2=656%, s3=832%, s4=513%, s5=540%, s6=593%, s7=564%, s8=563%, s9=701%]  (sum=5535%)
artifacts[sma-only]: 6f86408eff3edb14
cpu#1: last:  [s1=567840123, s2=573149880, s3=572128658, s4=558191135, s5=557130274, s6=572010916, s7=560523616, s8=556737567, s9=556616502] (stddev=6901582.77, mean=563814296.78, sum=5074328671)
cpu#1: thrash_pct: [s1=64%, s2=100%, s3=97%, s4=41%, s5=44%, s6=48%, s7=33%, s8=12%, s9=12%]  (sum=451%)
leases#1: first: [s1=36, s2=0, s3=0, s4=36, s5=0, s6=0, s7=36, s8=0, s9=0] (stddev=16.97, mean=12.00, sum=108)
leases#1: last:  [s1=10, s2=9, s3=9, s4=17, s5=12, s6=11, s7=15, s8=13, s9=12] (stddev=2.54, mean=12.00, sum=108)
leases#1: thrash_pct: [s1=77%, s2=78%, s3=72%, s4=52%, s5=50%, s6=56%, s7=46%, s8=27%, s9=8%]  (sum=466%)
replicas#1: first: [s1=36, s2=36, s3=36, s4=36, s5=36, s6=36, s7=36, s8=36, s9=36] (stddev=0.00, mean=36.00, sum=324)
replicas#1: last:  [s1=36, s2=36, s3=37, s4=35, s5=38, s6=35, s7=37, s8=34, s9=36] (stddev=1.15, mean=36.00, sum=324)
replicas#1: thrash_pct: [s1=500%, s2=350%, s3=227%, s4=127%, s5=380%, s6=302%, s7=277%, s8=180%, s9=100%]  (sum=2444%)
write_bytes_per_second#1: last:  [s1=5586, s2=5440, s3=5496, s4=6027, s5=6503, s6=5950, s7=6311, s8=5827, s9=6271] (stddev=358.51, mean=5934.56, sum=53411)
write_bytes_per_second#1: thrash_pct: [s1=1083%, s2=978%, s3=1008%, s4=743%, s5=739%, s6=729%, s7=663%, s8=637%, s9=543%]  (sum=7123%)
artifacts[mma-only]: 8ecbe79230fab769
cpu#1: last:  [s1=572415460, s2=566578888, s3=569096957, s4=556745916, s5=570328363, s6=558184663, s7=560070762, s8=557855218, s9=558141451] (stddev=5893908.39, mean=563268630.89, sum=5069417678)
cpu#1: thrash_pct: [s1=180%, s2=159%, s3=168%, s4=66%, s5=39%, s6=45%, s7=145%, s8=58%, s9=43%]  (sum=903%)
leases#1: first: [s1=36, s2=0, s3=0, s4=36, s5=0, s6=0, s7=36, s8=0, s9=0] (stddev=16.97, mean=12.00, sum=108)
leases#1: last:  [s1=7, s2=10, s3=8, s4=17, s5=13, s6=13, s7=16, s8=12, s9=12] (stddev=3.13, mean=12.00, sum=108)
leases#1: thrash_pct: [s1=149%, s2=130%, s3=124%, s4=70%, s5=33%, s6=33%, s7=140%, s8=56%, s9=44%]  (sum=778%)
replicas#1: first: [s1=36, s2=36, s3=36, s4=36, s5=36, s6=36, s7=36, s8=36, s9=36] (stddev=0.00, mean=36.00, sum=324)
replicas#1: last:  [s1=36, s2=34, s3=36, s4=37, s5=36, s6=36, s7=37, s8=36, s9=36] (stddev=0.82, mean=36.00, sum=324)
replicas#1: thrash_pct: [s1=150%, s2=455%, s3=325%, s4=127%, s5=125%, s6=150%, s7=352%, s8=150%, s9=150%]  (sum=1985%)
write_bytes_per_second#1: last:  [s1=5194, s2=5256, s3=5415, s4=6318, s5=6216, s6=6171, s7=6283, s8=6298, s9=6257] (stddev=461.69, mean=5934.22, sum=53408)
write_bytes_per_second#1: thrash_pct: [s1=1721%, s2=1566%, s3=1458%, s4=714%, s5=542%, s6=570%, s7=1227%, s8=694%, s9=803%]  (sum=9293%)
artifacts[mma-and-count]: 4fab04c2e6adb6a5
