skip_under_ci
----

# Set every store's capacity to 512 GiB, we will later adjust just one store to
# have less free capacity.
gen_cluster nodes=5 store_byte_capacity=549755813888
----

gen_ranges ranges=500 bytes=300000000
----

gen_load rate=500 max_block=60000 min_block=60000
----

# Set the disk storage capacity of s5 to 100 GiB. This will necessitate
# shedding replicas from s5 continously as the workload fills up ranges.
set_capacity store=5 capacity=107374182400
----

# We will repeatedly hit the disk fullness threshold which causes shedding
# replicas on store 5. We should see s5 hovering right around 92.5-95%
# (the storage capacity threshold value).
eval duration=30m seed=42 metrics=(replicas,disk_fraction_used) cfgs=(mma-only)
----
disk_fraction_used#1: first: [s1=0.20, s2=0.20, s3=0.20, s4=0.20, s5=1.05] (stddev=0.34, mean=0.37, sum=2)
disk_fraction_used#1: last:  [s1=0.30, s2=0.31, s3=0.30, s4=0.30, s5=0.92] (stddev=0.25, mean=0.43, sum=2)
disk_fraction_used#1: thrash_pct: [s1=40%, s2=36%, s3=37%, s4=37%, s5=149%]  (sum=298%)
replicas#1: first: [s1=300, s2=300, s3=300, s4=300, s5=300] (stddev=0.00, mean=300.00, sum=1500)
replicas#1: last:  [s1=326, s2=329, s3=323, s4=328, s5=194] (stddev=53.04, mean=300.00, sum=1500)
replicas#1: thrash_pct: [s1=303%, s2=271%, s3=282%, s4=274%, s5=141%]  (sum=1271%)
artifacts[mma-only]: 4ce2d48018807e82
